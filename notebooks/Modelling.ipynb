{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>Modelling** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Resolve an error that I had with Cuda\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "## plt.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the columns in the .head() method\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dotenv variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the the path variable from dotenv\n",
    "project_path = os.getenv('Project_Path')[2:78]\n",
    "\n",
    "# Change notebook directory back one so that it can acess the data\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/processed/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the GPU\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Use the CPU\n",
    "    print(\"GPU is not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the GPU through the name cuda\n",
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fit function that takes the X-train, y-train, epochs and Batch Size and fits the model\n",
    "def train_model(X_train, y_train, epochs, batch_sizes, net):\n",
    "    y_train = np.array(y_train['Binary'])\n",
    "\n",
    "    # Create an instance of the model with the correct input_dim\n",
    "    model = net(X_train.shape[1])\n",
    "\n",
    "    # Check if the GPU is available and save it to device. If not use the cpu\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Move the model over to the device that is available\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    X_train_tensor = torch.Tensor(X_train.values).float().to(device)\n",
    "    y_train_tensor = torch.Tensor(y_train).float().to(device)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = epochs\n",
    "    batch_size = batch_sizes\n",
    "    global losses\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at the start of each epoch\n",
    "        indices = np.random.permutation(len(X_train_tensor))\n",
    "        shuffled_X = X_train_tensor[indices]\n",
    "        shuffled_y = y_train_tensor[indices]\n",
    "        \n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Mini-batch training\n",
    "        for i in range(0, len(X_train_tensor), batch_size):\n",
    "\n",
    "            batch_X = shuffled_X[i:i+batch_size]\n",
    "            batch_y = shuffled_y[i:i+batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print loss and accuracy\n",
    "            print(f'\\rEpoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(X_train_tensor)}], Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}', end = '\\r')\n",
    "        \n",
    "        losses.append(loss.item()) # type: ignore\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create a function that takes in the loss from the train_model as an argument\n",
    "def loss_plot(loss, param_k = False, ticks_k = False):\n",
    "    if ticks_k == False:\n",
    "        # Create a plot of the the epics and the losses for each epoch\n",
    "        plt.plot(range(1,len(loss) + 1), loss);\n",
    "        # Match the ticks to the epochs\n",
    "        plt.xticks(np.arange(1, len(loss) + 1));\n",
    "    else:\n",
    "        # Create a plot of the the epics and the losses for each epoch\n",
    "        plt.plot(range(ticks_k[0], ticks_k[1]), loss); # type: ignore\n",
    "        # Match the ticks to the epochs\n",
    "        plt.xticks(np.arange(ticks_k[0], ticks_k[1] + 1)); # type: ignore\n",
    "    if param_k == False:\n",
    "        # Label the x-axis of the graph\n",
    "        plt.xlabel(\"Epoch #\");\n",
    "    else:\n",
    "        # Label the x-axis of the graph\n",
    "        plt.xlabel(\"K - Value\");\n",
    "    # Label the y-axis of the graph\n",
    "    plt.ylabel(\"Cost\");\n",
    "    # Title the graph\n",
    "    plt.title(\"Model Cost\");\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate the model\n",
    "def eval_model(X_test, y_test, model, dig):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Move the model and data back to the CPU\n",
    "    model.to(\"cpu\")\n",
    "    X_test_tensor = torch.Tensor(X_test.values).float()\n",
    "\n",
    "    # Make Preds a global variable for the roc graph\n",
    "    global preds\n",
    "    # Perform predictions on the test set\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test_tensor)\n",
    "\n",
    "    # Convert the predictions tensor to a numpy array\n",
    "    preds = preds.numpy()\n",
    "\n",
    "    # Calculate the rootmean square\n",
    "    plt.plot(x = np.linspace(1, len(preds), 1), y = preds)\n",
    "    plt.plot(x = np.linspace(1, len(preds), 1), y = y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class Net from the parent class nn.Module\n",
    "class Net(nn.Module):\n",
    "    # Initialize the class with \n",
    "    def __init__(self, input_dim):\n",
    "        # Initialize nn.Module with super\n",
    "        super(Net, self).__init__()\n",
    "        # Create the first layer of the neural net\n",
    "        self.fc1 = nn.Linear(input_dim, 12)\n",
    "        # Create the middle layers of the network with 12 nodes that connect to 12 nodes\n",
    "        self.fc2 = nn.Linear(12, 12)\n",
    "        self.fc3 = nn.Linear(12, 12)\n",
    "        self.fc4 = nn.Linear(12, 12)\n",
    "        # Create a layer that has 12 nodes that connect to 8 nodes\n",
    "        self.fc5 = nn.Linear(12, 8)\n",
    "        # Create the last layer that takes 8 nodes and compresses it down to 1\n",
    "        self.fc6 = nn.Linear(8, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Define a method for the forward propagation of the model\n",
    "    def forward(self, x):\n",
    "        # Create the connections \n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.activation(self.fc5(x))\n",
    "        x = self.sigmoid(self.fc6(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random forest model\n",
    "rf = RandomForestClassifier(n_jobs = 4)\n",
    "# Create a set of values to search\n",
    "param_grid = {'n_estimators': [5, 50, 100, 150, 200, 300, 600]}  \n",
    "# Create the grid search object with 5 cross validational folds\n",
    "grid_search = GridSearchCV(rf, param_grid, cv = 2, verbose = 1)  \n",
    "# Fit the data to the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Save the best parameters  \n",
    "best_params = grid_search.best_params_\n",
    "# Print the best parameters\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
